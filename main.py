import telebot
from telebot import types
from transformers import FSMTForConditionalGeneration, FSMTTokenizer

bot = telebot.TeleBot('6284659931:AAGW4k18XPA9HlYwUobf8h2yeCClwSasVcI')

global answers
answers = []
answers.append('no command')


@bot.message_handler(commands=['start'])
def start(message):

    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    btn1 = types.KeyboardButton("üëã –ü–æ–∑–¥–æ—Ä–æ–≤–∞—Ç—å—Å—è")
    markup.add(btn1)
    bot.send_message(message.from_user.id, "üëã –ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –±–æ—Ç-–ø–æ–º–æ—à–Ω–∏–∫!", reply_markup=markup)

@bot.message_handler(content_types=['text'])
def get_text_messages(message):

    if message.text == 'üëã –ü–æ–∑–¥–æ—Ä–æ–≤–∞—Ç—å—Å—è':
        markup = types.ReplyKeyboardMarkup(resize_keyboard=True) #—Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∫–Ω–æ–ø–æ–∫
        btn1 = types.KeyboardButton('–í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–æ–º')
        btn2 = types.KeyboardButton('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ñ—Ä–∞–∑—É')
        btn3 = types.KeyboardButton('–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç')
        markup.add(btn1, btn2, btn3)
        bot.send_message(message.from_user.id, '‚ùì –ù—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ', reply_markup=markup) #–æ—Ç–≤–µ—Ç –±–æ—Ç–∞


    elif message.text == "–í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–æ–º":

        '''mname = "facebook/wmt19-ru-en"
        tokenizer = FSMTTokenizer.from_pretrained(mname)
        model = FSMTForConditionalGeneration.from_pretrained(mname)

        input = message.text
        input_ids = tokenizer.encode(input, return_tensors="pt")
        outputs = model.generate(input_ids)
        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(decoded)  # Machine learning is great, isn't it?'''
        answers.append('translate')

        bot.send_message(message.from_user.id, '–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º',  parse_mode='Markdown')

    elif message.text == '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ñ—Ä–∞–∑—É':
        bot.send_message(message.from_user.id, '–ò–∑–≤–∏–Ω–∏—Ç–µ, —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ :(', parse_mode='Markdown')
        answers.append('phrase')

    elif message.text == '–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç':
        bot.send_message(message.from_user.id, '–ò–∑–≤–∏–Ω–∏—Ç–µ, —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ :(', parse_mode='Markdown')
        answers.append('generate')
    else:


        if answers[len(answers)-1] == "translate":
            mname = "facebook/wmt19-ru-en"
            tokenizer = FSMTTokenizer.from_pretrained(mname)
            model = FSMTForConditionalGeneration.from_pretrained(mname)

            input = message.text
            input_ids = tokenizer.encode(input, return_tensors="pt")
            outputs = model.generate(input_ids)
            decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
            print(decoded)  # Machine learning is great, isn't it?

            bot.send_message(message.from_user.id, decoded, parse_mode='Markdown')



bot.polling(none_stop=True, interval=0) #–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞ —á–∞—Å—Ç—å